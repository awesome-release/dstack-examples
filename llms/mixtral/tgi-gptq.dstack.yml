type: service
# This service deploys Mixtral (GPTQ) with TGI. Learn more at https://dstack.ai/examples/tgi/ or https://dstack.ai/examples/mixtral/
# Requires 25GB of total GPU memory

image: ghcr.io/huggingface/text-generation-inference:latest

env:
  - MODEL_ID=TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ

commands:
  - text-generation-server download-weights $MODEL_ID --trust-remote-code
  - text-generation-launcher
    --port 80
    --trust-remote-code
    --quantize gptq
port: 80

# Optional mapping for OpenAI-compatible endpoint
model:
  type: chat
  name: TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ
  format: tgi
